{
	"name": "1_Writing_data_to_processed_container",
	"properties": {
		"nbformat": 4,
		"nbformat_minor": 2,
		"sessionProperties": {
			"driverMemory": "28g",
			"driverCores": 4,
			"executorMemory": "28g",
			"executorCores": 4,
			"numExecutors": 2,
			"runAsWorkspaceSystemIdentity": false,
			"conf": {
				"spark.dynamicAllocation.enabled": "false",
				"spark.dynamicAllocation.minExecutors": "2",
				"spark.dynamicAllocation.maxExecutors": "2",
				"spark.autotune.trackingId": "ab474380-4c2d-415f-a522-7d125922d168"
			}
		},
		"metadata": {
			"saveOutput": true,
			"synapse_widget": {
				"version": "0.1"
			},
			"enableDebugMode": false,
			"language_info": {
				"name": "python"
			},
			"sessionKeepAliveTimeout": 30
		},
		"cells": [
			{
				"cell_type": "code",
				"source": [
					"mssparkutils.notebook.run('4 - MSSpark Utilities/6 - Mount configuration')"
				],
				"execution_count": 2
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"## - Accessing the Files from Mountpoint \r\n",
					"## Syntax:\r\n",
					"# synfs:/<jobid>/<mountpoint>/<path>\r\n",
					"# To get JobID - mssparkutils.env.getJobId()\r\n",
					"\r\n",
					"\r\n",
					"job_id = mssparkutils.env.getJobId()\r\n",
					"\r\n",
					"mount_point = 'synfs:/' + job_id + '/lake'"
				],
				"execution_count": 3
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"## Reading the previous Schema data to a dataframe\r\n",
					"\r\n",
					"df = spark.read.format('parquet')\\\r\n",
					"                .option('header','true')\\\r\n",
					"                .load(mount_point+'/SchemaManagement/*.parquet')\r\n",
					"\r\n",
					""
				],
				"execution_count": 4
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"collapsed": false
				},
				"source": [
					"display(df)"
				],
				"execution_count": 5
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"df.write.format('parquet')\\\r\n",
					"        .mode('overwrite')\\\r\n",
					"        .save('abfss://processed@projectsynapsestorage.dfs.core.windows.net/processed/')"
				],
				"execution_count": 9
			}
		]
	}
}